{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62cc7bf",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-15T10:03:11.523953Z",
     "iopub.status.busy": "2025-06-15T10:03:11.523572Z",
     "iopub.status.idle": "2025-06-15T10:03:20.890583Z",
     "shell.execute_reply": "2025-06-15T10:03:20.889698Z"
    },
    "papermill": {
     "duration": 9.374187,
     "end_time": "2025-06-15T10:03:20.892107",
     "exception": false,
     "start_time": "2025-06-15T10:03:11.517920",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78dfd58",
   "metadata": {
    "papermill": {
     "duration": 0.002556,
     "end_time": "2025-06-15T10:03:20.898116",
     "exception": false,
     "start_time": "2025-06-15T10:03:20.895560",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this task you will have to solve a standard problem on tabular data. However, the final solution must be obtained using the function **clf_train**.\n",
    "\n",
    "## Metric\n",
    "\n",
    "squared [RMSE](https://en.wikipedia.org/wiki/Root_mean_square_deviation) \n",
    "$$ SCORE = (\\sum_{i=1}^{n}{(true_i - predict_i)^{2}}/n)^{1/4} $$\n",
    "* **true** - real value of target\n",
    "* **predict** - your predict\n",
    "* **n** - length of target\n",
    "\n",
    "## Restriction\n",
    "\n",
    "You cannot change the code of the **clf_train** function. You can only use submissions produced by this function. This function takes the following s input: training and test datasets with the features preprocessed by you, weights of target for training, id column for generating the sample_submission.csv and function for inverting the target. \n",
    "\n",
    "## Data\n",
    "\n",
    "* **train_tables.csv** - train dataset with 9 numeric features, 3 datetime features and target\n",
    "* **test_tables.csv** - test dataset with 9 numeric features, 3 datetime features and id for submission\n",
    "* **sample_submission.csv** -  example of submission file with id coluns and target column that needed to predict."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3b3568",
   "metadata": {
    "papermill": {
     "duration": 0.003066,
     "end_time": "2025-06-15T10:03:20.903937",
     "exception": false,
     "start_time": "2025-06-15T10:03:20.900871",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "read train and test dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf1dcc80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-15T10:03:20.911656Z",
     "iopub.status.busy": "2025-06-15T10:03:20.911019Z",
     "iopub.status.idle": "2025-06-15T10:03:21.194649Z",
     "shell.execute_reply": "2025-06-15T10:03:21.193689Z"
    },
    "papermill": {
     "duration": 0.289243,
     "end_time": "2025-06-15T10:03:21.196214",
     "exception": false,
     "start_time": "2025-06-15T10:03:20.906971",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('/kaggle/input/neoai-2025-tricy-table-data/train_tables.csv')\n",
    "test = pd.read_csv('/kaggle/input/neoai-2025-tricy-table-data/test_tables.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1856381b",
   "metadata": {
    "papermill": {
     "duration": 0.002504,
     "end_time": "2025-06-15T10:03:21.201752",
     "exception": false,
     "start_time": "2025-06-15T10:03:21.199248",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Inference function\n",
    "\n",
    "**You cannot change this function.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558ea03a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-15T10:03:21.208290Z",
     "iopub.status.busy": "2025-06-15T10:03:21.207950Z",
     "iopub.status.idle": "2025-06-15T10:03:21.214053Z",
     "shell.execute_reply": "2025-06-15T10:03:21.213238Z"
    },
    "papermill": {
     "duration": 0.011058,
     "end_time": "2025-06-15T10:03:21.215464",
     "exception": false,
     "start_time": "2025-06-15T10:03:21.204406",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clf_train(train, test, target, weight_col, id_col, name_file = 'sub.csv', func_inv=None):\n",
    "\n",
    "    param = {\n",
    "    'learning_rate': 0.1,\n",
    "    'num_leaves': 48,\n",
    "    'lambda_l1' : 1,\n",
    "    'lambda_l2' : 1,\n",
    "    'min_data_in_leaf' : 100,\n",
    "    'objective': 'mae',\n",
    "    'verbosity':-1,\n",
    "    }\n",
    "    \n",
    "    predict_test = np.zeros(len(test))\n",
    "\n",
    "    tr = lgb.Dataset(train, target, weight=weight_col)\n",
    "    bst = lgb.train(param, tr, num_boost_round=500)\n",
    "    predict_test = bst.predict(test)\n",
    "    if func_inv:\n",
    "        predict_test = func_inv(predict_test)\n",
    "\n",
    "    sub = pd.DataFrame()\n",
    "    sub['id'] = id_col\n",
    "    sub['target'] = predict_test\n",
    "    sub.to_csv(name_file, index = None)\n",
    "  \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d249baac",
   "metadata": {
    "papermill": {
     "duration": 0.002489,
     "end_time": "2025-06-15T10:03:21.222017",
     "exception": false,
     "start_time": "2025-06-15T10:03:21.219528",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Function to change target if you need it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d95457b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-15T10:03:21.228628Z",
     "iopub.status.busy": "2025-06-15T10:03:21.228311Z",
     "iopub.status.idle": "2025-06-15T10:03:21.232454Z",
     "shell.execute_reply": "2025-06-15T10:03:21.231625Z"
    },
    "papermill": {
     "duration": 0.009106,
     "end_time": "2025-06-15T10:03:21.233825",
     "exception": false,
     "start_time": "2025-06-15T10:03:21.224719",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def func_inv(x):\n",
    "    # This function inverts the power transformation applied to the target during training.\n",
    "    # Since the evaluation metric is RMSE with a 4th root applied,\n",
    "    # I trained the model on the 4th root of the target (train['target']** 0.25) to linearize the loss,\n",
    "    # and used this inverse function (x^4) to return predictions to their original scale.\n",
    "    x = x ** 4\n",
    "    return x "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d41b72",
   "metadata": {
    "papermill": {
     "duration": 0.002575,
     "end_time": "2025-06-15T10:03:21.239483",
     "exception": false,
     "start_time": "2025-06-15T10:03:21.236908",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Train and inference. \n",
    "You should use **clf_train** for generating submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990de985",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-15T10:03:21.246636Z",
     "iopub.status.busy": "2025-06-15T10:03:21.246351Z",
     "iopub.status.idle": "2025-06-15T10:03:24.374729Z",
     "shell.execute_reply": "2025-06-15T10:03:24.373516Z"
    },
    "papermill": {
     "duration": 3.134276,
     "end_time": "2025-06-15T10:03:24.376616",
     "exception": false,
     "start_time": "2025-06-15T10:03:21.242340",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#Here, I impute `feat_1` and `feat_8` in the test data based on their mean values within each (day, hour) time window. \n",
    "#This was done by grouping the clean part of the test data and merging the group statistics back in to fill the gaps.\n",
    "\n",
    "\n",
    "test_clean = test.dropna(subset=['day', 'hour']).copy()\n",
    "# Compute mean for feat_1 and feat_8 per (day, hour)\n",
    "group_test_means = test_clean.groupby(['day', 'hour'])[['feat_1', 'feat_8']].mean().reset_index()\n",
    "test = test.merge(group_test_means, on=['day', 'hour'], how='left', suffixes=('', '_time_mean'))\n",
    "test['feat_1'] = test['feat_1'].fillna(test['feat_1_time_mean'])\n",
    "test['feat_8'] = test['feat_8'].fillna(test['feat_8_time_mean'])\n",
    "test.drop(columns=['feat_1_time_mean', 'feat_8_time_mean'])\n",
    "\n",
    "drop_cols = ['target']\n",
    "train_cols = [c for c in train.columns if c not in drop_cols]\n",
    "weight = np.ones(len(train))\n",
    "test_sub = clf_train(train[train_cols], test[train_cols], train['target']** 0.25 , weight, test['id'].tolist(), 'submission.csv', func_inv = func_inv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b77c45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-15T10:03:24.437255Z",
     "iopub.status.busy": "2025-06-15T10:03:24.436880Z",
     "iopub.status.idle": "2025-06-15T10:03:24.535343Z",
     "shell.execute_reply": "2025-06-15T10:03:24.534294Z"
    },
    "papermill": {
     "duration": 0.104581,
     "end_time": "2025-06-15T10:03:24.537455",
     "exception": false,
     "start_time": "2025-06-15T10:03:24.432874",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    day  hour     feat_0      feat_1    feat_2    feat_3     feat_4    feat_5  \\\n",
      "0   1.0   3.0  68.318174   35.154312  0.161525  1.645722  24.300528  5.032904   \n",
      "1   1.0   4.0  32.708355   29.140498  0.163607  1.940780  18.415738  3.206455   \n",
      "2   1.0   5.0  55.050122  149.877779  0.164393  4.026098  26.455074  4.527512   \n",
      "3   1.0   6.0  65.085840   45.206753  0.161610  3.438532  24.638165  4.585673   \n",
      "4   1.0   7.0  72.455214   19.098902  0.153890  4.968696  18.054194  5.117336   \n",
      "5   1.0   8.0  49.415961   20.245195  0.158357  3.234293  17.899657  3.861229   \n",
      "6   1.0   9.0  47.534170  111.305035  0.153543  3.402877  21.417155  3.510116   \n",
      "7   1.0  10.0  50.198807   27.179672  0.156781  3.483692  18.005464  3.585000   \n",
      "8   1.0  11.0  37.262027   23.611157  0.151215  2.644291  18.356149  2.642663   \n",
      "9   1.0  12.0  41.815335   21.798794  0.154236  2.988080  17.801661  3.129901   \n",
      "10  1.0  13.0  35.620418   34.256741  0.159014  2.364941  17.869114  2.510433   \n",
      "11  1.0  14.0  54.024655   21.630419  0.154781  3.068744  17.401777  3.468417   \n",
      "12  1.0  15.0  46.686703   25.247989  0.156212  3.120932  18.934160  3.152466   \n",
      "13  1.0  16.0  49.002063   32.987829  0.161114  2.553955  17.444751  2.617915   \n",
      "14  1.0  17.0  50.494780   30.402795  0.156025  3.550472  17.879787  3.185757   \n",
      "15  1.0  18.0  55.443291   25.099667  0.150304  4.234068  18.156929  4.172910   \n",
      "16  1.0  19.0  44.334733   57.698905  0.144805  3.460496  18.554655  2.859558   \n",
      "17  1.0  20.0  61.632243   29.725635  0.144756  4.015098  18.053774  3.349140   \n",
      "18  1.0  21.0  38.102557   28.382918  0.154789  3.190600  17.614969  3.740711   \n",
      "19  1.0  22.0  43.769351   24.248506  0.154558  1.826049  23.051026  3.153638   \n",
      "20  1.0  23.0  58.931753   23.047060  0.155088  4.228034  21.699203  3.626908   \n",
      "21  2.0   0.0  43.727354   19.020293  0.155892  2.626947  18.902009  3.209124   \n",
      "22  2.0   1.0  51.140224   17.611226  0.155230  3.614982  18.540922  3.215426   \n",
      "23  2.0   2.0  63.571859   20.846801  0.157930  3.659861  18.008167  3.998302   \n",
      "24  2.0   3.0  58.558071   40.853820  0.163848  3.547891  26.900823  4.251809   \n",
      "25  2.0   4.0  66.718106   41.658503  0.158157  3.714938  20.146115  4.493638   \n",
      "26  2.0   5.0  69.711462   69.040840  0.161965  4.546608  20.902196  4.039027   \n",
      "27  2.0   6.0  57.207329   75.452970  0.158878  3.893720  23.256343  4.134774   \n",
      "28  2.0   7.0  55.423054   33.126171  0.157822  3.338103  24.492100  3.781032   \n",
      "29  2.0   8.0  47.398383  131.634477  0.164813  2.955203  24.144028  3.208818   \n",
      "30  2.0   9.0  43.376138   39.700903  0.153406  3.140381  26.461774  3.230170   \n",
      "31  2.0  10.0  27.164450   15.402342  0.160833  1.507732  20.186671  1.927523   \n",
      "32  2.0  11.0  44.241104   22.937341  0.156543  3.090365  20.002718  3.398538   \n",
      "33  2.0  12.0  37.013778   76.424878  0.155324  1.835811  27.385312  2.618126   \n",
      "34  2.0  13.0   3.995927   17.994541  0.149895  0.587401  20.658841  0.435350   \n",
      "35  2.0  14.0   3.704375   20.804867  0.160221  0.495185  23.742474  0.357789   \n",
      "36  2.0  15.0  64.646174   19.386923  0.159936  4.231028  17.625306  3.435620   \n",
      "37  2.0  16.0  10.015824   62.819399  0.148770  0.692647  23.520807  0.644948   \n",
      "38  2.0  17.0  10.422212   60.657354  0.133791  2.306630  33.842969  3.509846   \n",
      "\n",
      "        feat_6      feat_7    feat_8  feat_0_rel_std  feat_1_rel_std  \\\n",
      "0   510.014298  161.514142  4.017695        0.953360        0.099966   \n",
      "1   378.155009  172.311864  3.819067        0.456436        0.082865   \n",
      "2   404.451531  189.725853  3.977583        0.768209        0.426197   \n",
      "3   425.415416  204.511780  3.984256        0.908254        0.128551   \n",
      "4   564.654659  281.305758  3.908918        1.011092        0.054310   \n",
      "5   379.754241  109.187339  3.664645        0.689585        0.057570   \n",
      "6   369.130894  159.437330  4.252787        0.663326        0.316510   \n",
      "7   352.048404  165.417929  3.968590        0.700510        0.077289   \n",
      "8   266.138953  138.852799  3.866736        0.519981        0.067141   \n",
      "9   300.181216  131.803837  3.922471        0.583521        0.061988   \n",
      "10  150.290781  105.588318  3.812348        0.497073        0.097413   \n",
      "11  384.794635  189.774328  3.776535        0.753898        0.061509   \n",
      "12  304.764658  186.081003  3.849708        0.651499        0.071796   \n",
      "13  264.981785  187.649939  3.801689        0.683810        0.093805   \n",
      "14  361.021781  179.778455  3.948931        0.704640        0.086454   \n",
      "15  382.928513  217.148941  3.904202        0.773695        0.071374   \n",
      "16  318.284982   90.341152  3.911215        0.618678        0.164074   \n",
      "17  397.421982  220.501549  3.896164        0.860060        0.084529   \n",
      "18  315.285824  182.457156  3.867964        0.531710        0.080710   \n",
      "19  313.964947   89.492378  4.254789        0.610789        0.068954   \n",
      "20  404.078069  225.072619  3.980186        0.822376        0.065537   \n",
      "21  331.443769  136.894032  3.877061        0.610203        0.054087   \n",
      "22  358.136038  187.038026  3.800922        0.713647        0.050080   \n",
      "23  449.942624  232.272030  3.843818        0.887127        0.059281   \n",
      "24  418.058893  158.230541  4.088525        0.817161        0.116173   \n",
      "25  156.216071  237.633620  3.866534        0.931032        0.118461   \n",
      "26  339.834031  237.320785  4.128412        0.972803        0.196326   \n",
      "27  374.254562  190.523106  4.165619        0.798312        0.214560   \n",
      "28  386.475200  201.192400  3.893189        0.773413        0.094199   \n",
      "29  321.525324  192.810793  4.290152        0.661431        0.374320   \n",
      "30  300.423368  211.694442  5.450640        0.605301        0.112895   \n",
      "31  183.398484  140.719684  5.174947        0.379072        0.043799   \n",
      "32  313.543659  242.292734  5.684463        0.617372        0.065225   \n",
      "33  250.208729  186.101820  9.579881        0.516517        0.217324   \n",
      "34   19.694536    7.578416  7.117104        0.055762        0.051170   \n",
      "35   22.262569    7.038896  9.396235        0.051693        0.059161   \n",
      "36  349.097010  359.038206  7.112324        0.902119        0.055129   \n",
      "37   59.949141  396.651187  8.988133        0.139768        0.178635   \n",
      "38  429.417306    4.503591  4.891346        0.145439        0.172487   \n",
      "\n",
      "    feat_2_rel_std  feat_3_rel_std  feat_4_rel_std  feat_5_rel_std  \\\n",
      "0         1.030315        0.353712        0.566593        1.015710   \n",
      "1         1.043593        0.417128        0.429383        0.647107   \n",
      "2         1.048605        0.865321        0.616828        0.913715   \n",
      "3         1.030859        0.739037        0.574465        0.925452   \n",
      "4         0.981614        1.067912        0.420953        1.032749   \n",
      "5         1.010108        0.695140        0.417350        0.779250   \n",
      "6         0.979396        0.731374        0.499364        0.708390   \n",
      "7         1.000056        0.748743        0.419817        0.723503   \n",
      "8         0.964547        0.568332        0.427993        0.533326   \n",
      "9         0.983821        0.642222        0.415065        0.631657   \n",
      "10        1.014294        0.508292        0.416638        0.506640   \n",
      "11        0.987294        0.659559        0.405741        0.699975   \n",
      "12        0.996423        0.670776        0.441470        0.636211   \n",
      "13        1.027694        0.548917        0.406743        0.528331   \n",
      "14        0.995230        0.763096        0.416886        0.642930   \n",
      "15        0.958741        0.910020        0.423348        0.842151   \n",
      "16        0.923660        0.743758        0.432622        0.577098   \n",
      "17        0.923353        0.862957        0.420943        0.675903   \n",
      "18        0.987348        0.685749        0.410712        0.754927   \n",
      "19        0.985872        0.392469        0.537459        0.636448   \n",
      "20        0.989251        0.908723        0.505940        0.731960   \n",
      "21        0.994381        0.564605        0.440721        0.647646   \n",
      "22        0.990159        0.776961        0.432301        0.648918   \n",
      "23        1.007385        0.786607        0.419880        0.806913   \n",
      "24        1.045130        0.762541        0.627222        0.858074   \n",
      "25        1.008832        0.798444        0.469728        0.906879   \n",
      "26        1.033123        0.977193        0.487357        0.815132   \n",
      "27        1.013428        0.836869        0.542247        0.834455   \n",
      "28        1.006693        0.717452        0.571060        0.763065   \n",
      "29        1.051287        0.635156        0.562944        0.647584   \n",
      "30        0.978522        0.674956        0.616985        0.651893   \n",
      "31        1.025902        0.324054        0.470674        0.389001   \n",
      "32        0.998538        0.664206        0.466385        0.685872   \n",
      "33        0.990757        0.394567        0.638518        0.528374   \n",
      "34        0.956132        0.126249        0.481683        0.087860   \n",
      "35        1.021995        0.106429        0.553581        0.072207   \n",
      "36        1.020178        0.909366        0.410953        0.693356   \n",
      "37        0.948954        0.148869        0.548413        0.130159   \n",
      "38        0.853410        0.495759        0.789085        0.708336   \n",
      "\n",
      "    feat_6_rel_std  feat_7_rel_std  feat_8_rel_std  \n",
      "0         1.033077        0.779490        0.252360  \n",
      "1         0.765985        0.831601        0.239884  \n",
      "2         0.819250        0.915644        0.249841  \n",
      "3         0.861715        0.987003        0.250260  \n",
      "4         1.143755        1.357621        0.245528  \n",
      "5         0.769224        0.526954        0.230184  \n",
      "6         0.747706        0.769467        0.267127  \n",
      "7         0.713104        0.798330        0.249276  \n",
      "8         0.539087        0.670123        0.242878  \n",
      "9         0.608042        0.636104        0.246379  \n",
      "10        0.304427        0.509584        0.239462  \n",
      "11        0.779434        0.915878        0.237212  \n",
      "12        0.617326        0.898053        0.241809  \n",
      "13        0.536743        0.905625        0.238792  \n",
      "14        0.731280        0.867636        0.248041  \n",
      "15        0.775654        1.047991        0.245231  \n",
      "16        0.644713        0.435999        0.245672  \n",
      "17        0.805012        1.064172        0.244727  \n",
      "18        0.638638        0.880564        0.242955  \n",
      "19        0.635962        0.431903        0.267253  \n",
      "20        0.818494        1.086232        0.250004  \n",
      "21        0.671367        0.660670        0.243527  \n",
      "22        0.725435        0.902672        0.238744  \n",
      "23        0.911396        1.120978        0.241439  \n",
      "24        0.846813        0.763643        0.256809  \n",
      "25        0.316429        1.146853        0.242865  \n",
      "26        0.688362        1.145344        0.259315  \n",
      "27        0.758084        0.919491        0.261652  \n",
      "28        0.782838        0.970983        0.244540  \n",
      "29        0.651276        0.930532        0.269474  \n",
      "30        0.608533        1.021667        0.342367  \n",
      "31        0.371489        0.679133        0.325050  \n",
      "32        0.635109        1.169339        0.357054  \n",
      "33        0.506819        0.898154        0.601733  \n",
      "34        0.039893        0.036575        0.447041  \n",
      "35        0.045095        0.033971        0.590198  \n",
      "36        0.707125        1.732769        0.446741  \n",
      "37        0.121432        1.914295        0.564564  \n",
      "38        0.869821        0.021735        0.307236  \n",
      "    day  hour      feat_0      feat_1    feat_2    feat_3     feat_4  \\\n",
      "0   1.0   3.0    5.938804   33.096362  0.156538  0.646683  26.235471   \n",
      "1   1.0   4.0   56.200619   26.383797  0.151529  3.645775  18.249033   \n",
      "2   1.0   5.0   82.715139  141.105061  0.155053  5.470866  26.073925   \n",
      "3   1.0   6.0   54.528501   41.584053  0.153373  3.211927  24.404667   \n",
      "4   1.0   7.0   80.007116   18.071255  0.153192  4.925141  18.292040   \n",
      "5   1.0   8.0   18.294408   18.789517  0.156232  4.437680  18.661794   \n",
      "6   1.0   9.0   53.074939  103.036377  0.156387  3.817935  23.388764   \n",
      "7   1.0  10.0   68.409866   29.046125  0.166961  5.037932  18.576496   \n",
      "8   1.0  11.0   37.983299   18.682310  0.163816  2.509052  17.876930   \n",
      "9   1.0  12.0   78.550222   17.385641  0.161844  4.971438  18.092964   \n",
      "10  1.0  13.0   49.724230   30.440790  0.162467  4.878299  18.030738   \n",
      "11  1.0  14.0   36.715016   19.573003  0.162655  4.157938  17.432171   \n",
      "12  1.0  15.0   51.514315   23.587268  0.150191  2.976163  19.300076   \n",
      "13  1.0  16.0   73.313435   31.261430  0.164246  5.149836  17.224697   \n",
      "14  1.0  17.0   52.443362   27.232069  0.154923  3.557505  17.556413   \n",
      "15  1.0  18.0   24.059832   25.086622  0.148707  2.032464  19.422722   \n",
      "16  1.0  19.0   35.844472   56.517139  0.147662  2.485120  19.877348   \n",
      "17  1.0  20.0  100.348900   28.728579  0.166743  5.388431  17.986259   \n",
      "18  1.0  21.0   18.503242   26.387384  0.162755  1.294369  16.760008   \n",
      "19  1.0  22.0    6.390368   24.483720  0.153256  0.673228  22.499652   \n",
      "20  1.0  23.0    7.427547   21.901442  0.161357  0.648256  21.842051   \n",
      "21  2.0   0.0   17.489838   18.970280  0.157285  1.384105  18.302974   \n",
      "22  2.0   1.0   73.662663   17.676704  0.167518  5.424419  17.738577   \n",
      "23  2.0   2.0   62.047383   19.302617  0.147065  4.109913  17.488854   \n",
      "24  2.0   3.0   35.014092   37.958032  0.143898  5.956478  26.218605   \n",
      "25  2.0   4.0   59.121698   37.852887  0.146329  3.876754  20.026795   \n",
      "26  2.0   5.0   52.923964   66.730761  0.158564  3.705440  21.264025   \n",
      "27  2.0   6.0   13.132852   69.371854  0.149524  0.769718  23.398919   \n",
      "28  2.0   7.0   33.893593   32.228140  0.151210  2.263950  24.892862   \n",
      "29  2.0   8.0   54.439992  122.411958  0.155380  4.642209  23.561132   \n",
      "30  2.0   9.0   54.917623   37.301258  0.162070  3.704051  25.624033   \n",
      "31  2.0  10.0   31.520138   15.083411  0.157653  1.603760  20.630346   \n",
      "32  2.0  11.0   55.598131   23.641188  0.164256  4.624336  19.753738   \n",
      "33  2.0  12.0   26.929233  100.859617  0.162955  1.350246  24.938529   \n",
      "34  2.0  13.0   30.112843   18.615329  0.157654  1.972578  19.914529   \n",
      "35  2.0  14.0   30.501940   21.011019  0.153337  3.419097  24.218471   \n",
      "36  2.0  15.0   11.090788   20.462025  0.154406  0.800674  17.463310   \n",
      "37  2.0  16.0   23.799414   59.879311  0.158689  1.975672  21.990760   \n",
      "38  2.0  17.0   12.818095   60.599244  0.162356  0.723510  37.652732   \n",
      "\n",
      "      feat_5      feat_6      feat_7     feat_8  feat_0_rel_std  \\\n",
      "0   0.477260   34.970119    8.875515   3.923081        0.072337   \n",
      "1   3.791228  387.892207  181.319079   3.611769        0.684549   \n",
      "2   6.242690  571.357035  189.272930   3.750715        1.007508   \n",
      "3   4.043322  413.602498    8.555233   3.847619        0.664182   \n",
      "4   4.206390  537.504445  145.335806   3.813839        0.974523   \n",
      "5   4.598788  442.660123  244.356971   3.568248        0.222834   \n",
      "6   3.707020  251.405973  129.585154   3.775072        0.646477   \n",
      "7   5.088664  456.724880  262.494824   3.739174        0.833263   \n",
      "8   2.614130  265.315705  159.136288   3.716065        0.462654   \n",
      "9   4.550678  358.316891  260.682992   3.635966        0.956778   \n",
      "10  5.062007  502.675623  232.441836   3.981038        0.605664   \n",
      "11  4.349899  435.851475  223.329832   3.761584        0.447206   \n",
      "12  3.662250  365.895499  187.012010   3.797011        0.627468   \n",
      "13  5.378916  454.056565  184.932381   3.634788        0.892991   \n",
      "14  3.641999  362.579845  181.076507   3.596168        0.638784   \n",
      "15  1.710122  167.605507   99.613327   3.743385        0.293060   \n",
      "16  2.803194  280.426539  152.635880   3.576400        0.436602   \n",
      "17  7.578762  715.734927  362.805312   3.684428        1.222296   \n",
      "18  1.359475  130.659641   64.688681   3.620527        0.225378   \n",
      "19  0.525137   25.309287    7.908211   3.793804        0.077838   \n",
      "20  0.513334   23.268494    7.945180   3.706975        0.090471   \n",
      "21  1.323276  128.024106   62.125868   3.571715        0.213034   \n",
      "22  5.368001  558.546908  291.897505   3.800367        0.897245   \n",
      "23  0.421927  458.841961  222.679468   3.602070        0.755766   \n",
      "24  4.586026  586.683365  266.498308   3.802913        0.426488   \n",
      "25  4.109713   39.095447  196.453250   3.931678        0.720129   \n",
      "26  3.846494  394.314158  184.785868   4.021648        0.644638   \n",
      "27  3.777025  378.558667  189.360085   3.711130        0.159964   \n",
      "28  2.389846  237.468036  120.200455   3.874902        0.412839   \n",
      "29  4.836150  463.709056  247.945098   4.061816        0.663104   \n",
      "30  2.924713  337.891293  266.710397   4.943556        0.668922   \n",
      "31  1.569118  215.799951  150.015229   4.816262        0.383930   \n",
      "32  2.515222  421.472740  290.423769   5.494718        0.677211   \n",
      "33  1.506458  170.587230   80.309344  11.884017        0.328010   \n",
      "34  2.071045  209.402540  161.173320   6.470058        0.366788   \n",
      "35  3.590585  383.817926  284.560953   8.589151        0.371528   \n",
      "36  0.752472   21.294266   76.589140   6.940289        0.135091   \n",
      "37  2.041636  220.113518  430.971227   7.988718        0.289888   \n",
      "38  0.644228   63.693404    4.494325   4.474124        0.156130   \n",
      "\n",
      "    feat_1_rel_std  feat_2_rel_std  feat_3_rel_std  feat_4_rel_std  \\\n",
      "0         0.074107        0.996993        0.114192        0.609838   \n",
      "1         0.059077        0.965091        0.643773        0.424195   \n",
      "2         0.315952        0.987535        0.966049        0.606082   \n",
      "3         0.093112        0.976837        0.567164        0.567281   \n",
      "4         0.040464        0.975683        0.869684        0.425194   \n",
      "5         0.042072        0.995041        0.783608        0.433789   \n",
      "6         0.230711        0.996029        0.674173        0.543666   \n",
      "7         0.065038        1.063379        0.889601        0.431806   \n",
      "8         0.041832        1.043347        0.443050        0.415545   \n",
      "9         0.038929        1.030785        0.877860        0.420567   \n",
      "10        0.068161        1.034755        0.861413        0.419120   \n",
      "11        0.043826        1.035950        0.734211        0.405207   \n",
      "12        0.052815        0.956569        0.525533        0.448626   \n",
      "13        0.069998        1.046085        0.909361        0.400384   \n",
      "14        0.060976        0.986706        0.628186        0.408095   \n",
      "15        0.056172        0.947118        0.358894        0.451477   \n",
      "16        0.126549        0.940462        0.438824        0.462044   \n",
      "17        0.064327        1.061989        0.951493        0.418086   \n",
      "18        0.059085        1.036591        0.228561        0.389583   \n",
      "19        0.054822        0.976088        0.118879        0.522999   \n",
      "20        0.049040        1.027685        0.114469        0.507713   \n",
      "21        0.042477        1.001751        0.244406        0.425448   \n",
      "22        0.039580        1.066921        0.957847        0.412329   \n",
      "23        0.043221        0.936658        0.725731        0.406524   \n",
      "24        0.084993        0.916488        1.051799        0.609446   \n",
      "25        0.084757        0.931973        0.684560        0.465518   \n",
      "26        0.149418        1.009896        0.654309        0.494277   \n",
      "27        0.155332        0.952320        0.135917        0.543903   \n",
      "28        0.072163        0.963058        0.399770        0.578629   \n",
      "29        0.274095        0.989617        0.819724        0.547673   \n",
      "30        0.083522        1.032229        0.654064        0.595625   \n",
      "31        0.033774        1.004091        0.283193        0.479548   \n",
      "32        0.052936        1.046151        0.816568        0.459171   \n",
      "33        0.225837        1.037860        0.238427        0.579690   \n",
      "34        0.041682        1.004100        0.348319        0.462909   \n",
      "35        0.047046        0.976606        0.603746        0.562953   \n",
      "36        0.045817        0.983411        0.141384        0.405931   \n",
      "37        0.134077        1.010694        0.348865        0.511170   \n",
      "38        0.135689        1.034047        0.127758        0.875229   \n",
      "\n",
      "    feat_5_rel_std  feat_6_rel_std  feat_7_rel_std  feat_8_rel_std  \n",
      "0         0.080832        0.060166        0.034518        0.132098  \n",
      "1         0.642106        0.667371        0.705171        0.121615  \n",
      "2         1.057300        0.983024        0.736104        0.126294  \n",
      "3         0.684802        0.711606        0.033272        0.129557  \n",
      "4         0.712420        0.924780        0.565228        0.128419  \n",
      "5         0.778879        0.761600        0.950333        0.120150  \n",
      "6         0.627844        0.432546        0.503972        0.127114  \n",
      "7         0.861848        0.785798        1.020873        0.125905  \n",
      "8         0.442745        0.456478        0.618899        0.125127  \n",
      "9         0.770731        0.616487        1.013826        0.122430  \n",
      "10        0.857333        0.864857        0.903993        0.134049  \n",
      "11        0.736726        0.749886        0.868556        0.126660  \n",
      "12        0.620261        0.629526        0.727311        0.127853  \n",
      "13        0.911006        0.781208        0.719223        0.122390  \n",
      "14        0.616831        0.623821        0.704228        0.121090  \n",
      "15        0.289637        0.288366        0.387408        0.126047  \n",
      "16        0.474766        0.482476        0.593619        0.120424  \n",
      "17        1.283586        1.231427        1.410992        0.124062  \n",
      "18        0.230249        0.224801        0.251582        0.121910  \n",
      "19        0.088940        0.043545        0.030756        0.127745  \n",
      "20        0.086941        0.040034        0.030900        0.124821  \n",
      "21        0.224118        0.220266        0.241615        0.120267  \n",
      "22        0.909158        0.960984        1.135223        0.127966  \n",
      "23        0.071460        0.789441        0.866026        0.121289  \n",
      "24        0.776718        1.009393        1.036443        0.128051  \n",
      "25        0.696046        0.067264        0.764029        0.132387  \n",
      "26        0.651466        0.678420        0.718654        0.135417  \n",
      "27        0.639700        0.651313        0.736443        0.124961  \n",
      "28        0.404759        0.408565        0.467473        0.130475  \n",
      "29        0.819080        0.797815        0.964287        0.136769  \n",
      "30        0.495347        0.581344        1.037268        0.166459  \n",
      "31        0.265756        0.371285        0.583427        0.162173  \n",
      "32        0.425994        0.725147        1.129492        0.185018  \n",
      "33        0.255143        0.293497        0.312332        0.400158  \n",
      "34        0.350765        0.360279        0.626822        0.217859  \n",
      "35        0.608124        0.660362        1.106691        0.289213  \n",
      "36        0.127443        0.036637        0.297864        0.233693  \n",
      "37        0.345784        0.378707        1.676097        0.268996  \n",
      "38        0.109110        0.109585        0.017479        0.150652  \n",
      "39\n"
     ]
    }
   ],
   "source": [
    "#To better understand how feature distributions evolve over time, \n",
    "#I computed the relative standard deviation of each feature within `(day, hour)` time windows. \n",
    "#This helped reveal whether certain features exhibited time-dependent variability.\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "feat_cols = [f'feat_{i}' for i in range(9)]\n",
    "\n",
    "# Drop rows where day or hour is NaN\n",
    "train_clean = train.dropna(subset=['day', 'hour']).copy()\n",
    "test_clean = test.dropna(subset=['day', 'hour']).copy()\n",
    "\n",
    "# Compute overall std for each feature (across whole dataset)\n",
    "overall_std = train_clean[feat_cols].std()\n",
    "overall_test_std = test_clean[feat_cols].std()\n",
    "\n",
    "# Compute group std per (day, hour)\n",
    "group_std = train_clean.groupby(['day', 'hour'])[feat_cols].std().reset_index()\n",
    "group_test_std = test_clean.groupby(['day', 'hour'])[feat_cols].std().reset_index()\n",
    "\n",
    "# Calculate relative std (group std / overall std)\n",
    "for feat in feat_cols:\n",
    "    group_std[f'{feat}_rel_std'] = group_std[feat] / overall_std[feat]\n",
    "\n",
    "for feat in feat_cols:\n",
    "    group_test_std[f'{feat}_rel_std'] = group_test_std[feat] / overall_test_std[feat]\n",
    "\n",
    "# Now group_std contains the relative std values per time group per feature\n",
    "train = train.merge(group_std[['day', 'hour'] + [f'{feat}_rel_std' for feat in feat_cols]], \n",
    "                    on=['day', 'hour'], how='left')\n",
    "\n",
    "test = test.merge(group_std[['day', 'hour'] + [f'{feat}_rel_std' for feat in feat_cols]], \n",
    "                  on=['day', 'hour'], how='left')\n",
    "\n",
    "\n",
    "print(group_test_std)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 12178557,
     "sourceId": 100977,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 19.272587,
   "end_time": "2025-06-15T10:03:25.462904",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-15T10:03:06.190317",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
